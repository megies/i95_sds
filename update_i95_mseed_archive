#!/usr/bin/env python
"""
Calculate I95 based on SDS waveform archive and FDSN server with station
metadata and store it in SDS structure in npy format.
"""
from __future__ import print_function
import json
import os
import pprint
import sys
import warnings
from argparse import ArgumentParser, RawDescriptionHelpFormatter

# we're not plotting anything, and obspy should also not make any matplotlib
# import that accidentally could set a backend, so this is really just in
# case.. to avoid unwanted interactive backends set on servers (which would
# lead to errors)
import matplotlib as mpl
mpl.use("AGG")

import numpy as np

from obspy import UTCDateTime
from obspy.clients.filesystem.sds import Client as SDSClient
from obspy.clients.fdsn import Client as FDSNClient
from obspy.clients.fdsn.header import FDSNException


# STREAMS = ["EH", "HH", "EL"]
# COMPONENTS = "ZNE123"
#
# # length of analysis window in minutes
# WINDOW_LENGTH_MINUTES = 10
# WINDOW_LENGTH = WINDOW_LENGTH_MINUTES * 60
# # length of buffer before start / after end for preprocessing,
# # cut off before analysis, in seconds
# BUFFER_LENGTH = 1 * 60
# # instrument correction parameters
# WATER_LEVEL = 10
# PRE_FILT = (0.05, 0.1, 50, 60)
# FILTER_PARAMETERS = {
#     'type': "bandpass",
#     'freqmin': 0.5,
#     'freqmax': 30,
#     'corners': 4,
#     'zerophase': False,
#     }
#
# OVERWRITE = True
# SDS_ROOT_MSEED = "/bay200/mseed_online/archive"
# SDS_ROOT_I95 = "/bay200/I95_0.5-30Hz"
# FDSN_BASE_URL = "http://jane.geophysik.uni-muenchen.de"


DTYPE = np.dtype([('i95', np.float32), ('coverage', np.uint8)])
I95_PARAM_FILENAME = 'parameters.json'
I95_TIMES_FILENAME = 'times.npy'


def _string_format_params(params):
    return "  " + "\n  ".join(pprint.pformat(params).splitlines())


def _setup_new_i95_root(directory, params, times):
    # create dir
    os.makedirs(directory)
    # make info files in I95 SDS root read-only for everybody
    old_umask = os.umask(0222)
    try:
        # store parameter settings
        json_string = json.dumps(params, ensure_ascii=True, indent=4,
                                 encoding='ASCII', sort_keys=True)
        i95_param_file = os.path.join(directory, I95_PARAM_FILENAME)
        with open(i95_param_file, 'wb') as fh:
            fh.write(json_string.encode('ASCII'))
        # store times as plain ndarray in npy
        i95_times_file = os.path.join(directory, I95_TIMES_FILENAME)
        np.save(i95_times_file, times)
        # set these files read-only for everybody
    finally:
        os.umask(old_umask)


def _sanity_check_i95_root(directory, params, times):
    # check directory
    if not os.path.isdir(directory):
        msg = ('I95 SDS root exists and is no directory')
        raise IOError(msg)
    # assert equality of processing parameters
    with open(os.path.join(directory, I95_PARAM_FILENAME), 'rb') as fh:
        json_string = fh.read().decode('ASCII')
    params_expected = json.loads(json_string, encoding='ASCII')
    if params != params_expected:

        msg = ('Processing parameters do not match processing parameters '
               'stored in I95 SDS root.\n Expected:\n{expected}\n Got:\n{got}')
        msg = msg.format(expected=_string_format_params(params_expected),
                         got=_string_format_params(params))
        raise Exception(msg)
    # assert equality of times (of day) corresponding to the stored I95 values
    times_expected = np.load(os.path.join(directory, I95_TIMES_FILENAME))
    try:
        np.testing.assert_array_equal(times_expected, times)
    except AssertionError as e:
        msg = ('Times (of day) of to-be-stored I95 data does not match the '
               'expected times stored in I95 SDS root:\n{}')
        msg = msg.format(str(e))
        raise Exception()


def _write_result_npy(filename, data):
    outdir = os.path.dirname(filename)
    if not os.path.isdir(outdir):
        os.makedirs(outdir)
    if np.all(data['coverage'] == 0) and np.all(data['i95'] == np.nan):
        # on empty data, write file with only content '0'
        # (would be easier to just touch an empty file but that could
        #  potentially be mixed up / mask other problems like file opening
        #  errors)
        with open(filename, 'wb') as fh:
            fh.write('0'.encode('ASCII'))
    else:
        np.save(filename, data)


def main(argv=None):
    parser = ArgumentParser(
        prog='update_i95_mseed_archive', description=__doc__.strip(),
        formatter_class=RawDescriptionHelpFormatter)

    options = parser.add_argument_group(
        'General Options', 'General options controlling what data is '
        'processed and where results are stored.')
    options.add_argument(
        '-t', '--time', dest='time', required=True,
        help='Year and day to process (e.g. "2017-12-24" or "2017-365").')
    options.add_argument(
        '--sds-root-waveforms', dest='sds_root_waveforms', required=True,
        type=str,
        help='Root directory of the SDS directory structure containing the '
             'waveform data (should contain subdirectories with years).')
    options.add_argument(
        '--sds-root-i95', dest='sds_root_i95', required=True, type=str,
        help='Root directory of the SDS directory structure used to store I95 '
             'data.')
    options.add_argument(
        '--fdsn-base-url', dest='fdsn_base_url', required=True, type=str,
        help='FDSN base url used in obspy FDSN Client. This server will be '
             'used to fetch station metadata used in deconvolution.')
    options.add_argument(
        '--stream', dest='streams', default=[], action='append', required=True,
        help='Stream to consider (i.e. first two characters of SEED channel '
             'code). This option can be specified multiple times (e.g. use '
             '"-s HH -s EH -s EL"). Other streams that are not specified will '
             'be ignored (e.g. in the example, lower sample rate streams like '
             'BHZ')
    options.add_argument(
        '--component-codes', dest='component_codes', type=str,
        default='ZNE123',
        help='Specifies which component codes are considered (i.e. last '
             'character of SEED channel code).')
    options.add_argument(
        '--station-code', dest='station_codes', default=[], action='append',
        help='Specifies whether only specific station(s) (SEED station code) '
             'should be considered. If not used, all stations available at a '
             'given day will be used. If specified, only the given station(s) '
             'will be processed. Can be specified multiple times to consider '
             'a few select stations.')
    options.add_argument(
        '--overwrite', dest='overwrite', default=False,
        action='store_true',
        help='Whether to overwrite already existing data. This can be used to '
             'force an update of already existing data (e.g. when archive '
             'data is added at a later point). Otherwise a given day is not '
             'processed if output for that day is already present.')
    options.add_argument(
        '-v', '--verbose', dest='verbose', default=False,
        action="store_true",
        help='Print verbose output while processing files.')

    options = parser.add_argument_group(
        '(Pre-)Processing Options', 'Settings regarding the details of '
        '(pre-)processing. An exception will be raised when trying to add '
        'data to an existing I95 SDS archive and a mismatch of processing '
        'settings is detected.')
    options.add_argument(
        '--window-length', dest='window_length_minutes', type=float,
        default=10,
        help='Specifies length of data window the I95 value is based on in '
             'minutes (this is the actual length, buffers will be added on '
             'top of this window and cut off after pre-processing).')
    options.add_argument(
        '--buffer-length', dest='buffer_length', type=float,
        default=120,
        help='Specifies length of waveform buffer both before and after '
             'actual window used during preprocessing in seconds.')
    options.add_argument(
        '--water-level', dest='water_level', required=True,
        help='Specifies "water_level" option in obspy '
             '"Stream.remove_response()" during preprocessing. Use a float '
             'value or "None" for no water level used in deconvolution.')
    options.add_argument(
        '--pre-filt', dest='pre_filt', required=True,
        help='Specifies "pre_filt" option in obspy "Stream.remove_response()" '
             'during preprocessing. Use four comma-separated floats (no '
             'spaces, e.g. "0.05,0.1,50,60") or "None" for no pre filter used '
             'in deconvolution.')
    options.add_argument(
        '--filter-type', dest='filter_type', required=True, type=str,
        help='Specifies which filter to use after deconvolution and before '
             'calculating I95. Use either "None", "bandpass", "lowpass" or '
             '"highpass". See obspy Stream.filter().')
    options.add_argument(
        '--filter-freq', dest='filter_freq', default=None, type=float,
        help='Specifies "freq" option for used filter. Only used when '
             '"lowpass" or "highpass" is selected.')
    options.add_argument(
        '--filter-freqmin', dest='filter_freqmin', default=None, type=float,
        help='Specifies "freqmin" option for used filter. Only used when '
             '"bandpass" is selected.')
    options.add_argument(
        '--filter-freqmax', dest='filter_freqmax', default=None, type=float,
        help='Specifies "freqmax" option for used filter. Only used when '
             '"bandpass" is selected.')
    options.add_argument(
        '--filter-corners', dest='filter_corners', default=None, type=int,
        help='Specifies "corners" option for used filter.')
    options.add_argument(
        '--filter-zerophase', dest='filter_zerophase', default=False,
        action='store_true',
        help='Whether to use a two-pass zero-phase filter (default is no '
             'zero-phase). Filter is applied twice if this option is '
             'selected.')

    args = parser.parse_args(argv)
    verbose = args.verbose
    window_length = args.window_length_minutes * 60
    buffer_length = args.buffer_length
    if args.water_level.upper() == 'NONE':
        water_level = None
    else:
        water_level = float(args.water_level)
    if args.pre_filt.upper() == 'NONE':
        pre_filt = None
    else:
        pre_filt = list(float(value) for value in args.pre_filt.split(','))
    if args.filter_type.upper() == 'NONE':
        use_filter = True
        filter_kwargs = {'type': None}
    else:
        use_filter = False
        filter_kwargs = {'type': args.filter_type}
    for key in ('filter_freq', 'filter_freqmin', 'filter_freqmax',
                'filter_corners'):
        value = getattr(args, key, None)
        if value is not None:
            filter_kwargs[key] = value
    filter_kwargs['zerophase'] = args.filter_zerophase

    # prepare dictionary with parameters to store/check in I95 SDS root
    params = dict(
        window_length_minutes=args.window_length_minutes,
        buffer_length=buffer_length, water_level=water_level,
        pre_filt=pre_filt, filter_kwargs=filter_kwargs)

    t = UTCDateTime(args.time)
    # work on the full day of the given timestamp
    year_day_string = t.strftime("%Y-%j")
    t = UTCDateTime(year_day_string)
    t_end = t + 24 * 3600
    if verbose:
        print('#' * 70)
        print('#' * 70)
        print('Processing ' + year_day_string)
        print('#' * 70)

    if t >= UTCDateTime():
        msg = 'Time to process is in the future ({!s})'.format(t)
        raise Exception(msg)

    # time-of-day in nanoseconds to represent times corresponding to I95 values
    times = np.arange(t._ns, t_end._ns,
                      int(window_length * 1e9), dtype=np.int64)
    times_of_day = times - t._ns

    # now check if processing is compatible with what is stored in I95 SDS
    if os.path.exists(args.sds_root_i95):
        if verbose:
            print('Sanity checking existing I95 SDS root at {}... '.format(
                args.sds_root_i95), end='')
        _sanity_check_i95_root(args.sds_root_i95, params, times_of_day)
        if verbose:
            print('done.')
    else:
        if verbose:
            print('Creating new I95 SDS root at ' + args.sds_root_i95)
        _setup_new_i95_root(args.sds_root_i95, params, times_of_day)

    if verbose:
        print('Connecting SDS/FDSN clients... ', end='')
    sds_client_mseed = SDSClient(args.sds_root_waveforms)
    fdsn_client = FDSNClient(args.fdsn_base_url)
    sds_client_npy = SDSClient(args.sds_root_i95)
    if verbose:
        print('done')
    sds_client_npy.FMTSTR += ".npy"

    if verbose:
        print('Fetching station inventory summary from FDSN client... ', end='')
    inv_all = fdsn_client.get_stations(
        level='channel', format='text', starttime=t - 100, endtime=t_end + 100)
    if verbose:
        print('done')

    # replaced because it is so slow..
    #  .. lookup SEED codes from fetched bare inventory
    # nslc = [(n, s, l, c)
    #         for (n, s, l, c) in sds_client_mseed.get_all_nslc(datetime=t)
    #         if c[:2] in args.streams and c[2] in args.component_codes]
    nslc = set()
    for net in inv_all:
        for sta in net:
            if args.station_codes and sta.code not in args.station_codes:
                continue
            for cha in sta:
                if cha.code[:2] not in args.streams:
                    continue
                if cha.code[2] not in args.component_codes:
                    continue
                nslc.add((net.code, sta.code, cha.location_code, cha.code))
    if verbose:
        print('Processing the following SEED IDs:\n  ' + '\n  '.join(
            ('.'.join(nslc_) for nslc_ in nslc)))
        print('-' * 70)

    def _process(net, sta, loc, cha, t, verbose=verbose):
        npy_file = sds_client_npy._get_filename(
            net, sta, loc, cha, t)

        if not args.overwrite and os.path.exists(npy_file):
            if verbose:
                print("Outfile exists and overwrite option not specified, "
                      "skipping: {}".format(npy_file))
            return

        inv = None
        try:
            if verbose:
                print('Fetching response information from FDSN client... ',
                      end='')
            inv = fdsn_client.get_stations(
                network=net, station=sta, location=loc, channel=cha,
                level="response", starttime=t - 100, endtime=t_end + 100)
        except FDSNException as e:
            if verbose:
                print('failed!')
            msg = ("Failed to fetch station metadata for '{}': "
                   "{}").format('.'.join(net, sta, loc, cha), str(e))
            warnings.warn(msg)
            return
        else:
            if verbose:
                print('done.')

        data = np.zeros(len(times), dtype=DTYPE)

        if verbose:
            print('{} windows to process: '.format(len(times)), end='')
        for i, t_ in enumerate(times):
            if verbose:
                if verbose and i % 5 == 0:
                    print(str(i), end='')
            data_ = []
            #    t0 ----------- t1 --------------------- t2 ----------- t3
            #          buffer           actual window          buffer
            t1 = UTCDateTime(ns=t_) - (window_length / 2.0)
            t2 = UTCDateTime(ns=t_) + (window_length / 2.0)
            t0 = t1 - buffer_length
            t3 = t2 + buffer_length
            st = sds_client_mseed.get_waveforms(net, sta, loc, cha, t0, t3)
            # cleanup merge..
            st.merge(-1)
            # now throw away gaps..
            st.merge(0, fill_value=None)
            st = st.split()
            # omit traces that are less than twice the buffer length and thus
            # can not be processed..
            st.traces = [
                tr for tr in st if
                (tr.stats.endtime - tr.stats.starttime) > 2 * buffer_length]
            if not st:
                if verbose:
                    print('x', end='')
                data['i95'][i] = np.nan
                data['coverage'][i] = 0
                continue
            coverage_ = 0
            for tr in st:
                coverage_ += (
                    tr.stats.endtime - tr.stats.starttime) / window_length
            for tr in st:
                tr.taper(type="cosine", max_percentage=None,
                         max_length=buffer_length, side="both")
                tr.remove_response(
                    inventory=inv, output="VEL", water_level=water_level,
                    pre_filt=pre_filt, zero_mean=False, taper=False)
                if use_filter:
                    tr.filter(**filter_kwargs)
                tr.detrend("demean")
                tr.trim(starttime=t1, endtime=t2)
                data_.append(np.abs(tr.data) * 1e9)  # work in nm/s
            data_ = np.concatenate(data_)
            data['i95'][i] = np.percentile(data_, 95)
            # save coverage in percent
            data['coverage'][i] = round(coverage_ * 100)
            if verbose:
                print('.', end='')
            sys.stdout.flush()
        if verbose:
            print(' done!')

        _write_result_npy(npy_file, data)

    total = len(nslc)
    for i, (net, sta, loc, cha) in enumerate(sorted(nslc)):
        if verbose:
            print('-' * 70)
            print('Processing SEED ID {}  ({!s}/{!s})'.format(
                '.'.join((net, sta, loc, cha)), i+1, total))
        _process(net, sta, loc, cha, t, verbose=verbose)


if __name__ == '__main__':
    main()
